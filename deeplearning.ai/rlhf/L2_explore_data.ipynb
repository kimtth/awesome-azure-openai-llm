{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088542f0",
   "metadata": {},
   "source": [
    "# Lesson 2: Datasets For Reinforcement Learning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08cfaf3",
   "metadata": {},
   "source": [
    "### Loading and exploring the datasets\n",
    "\n",
    "\"Reinforcement Learning from Human Feedback\" **(RLHF)** requires the following datasets:\n",
    "- Preference dataset\n",
    "  - Input prompt, candidate response 0, candidate response 1, choice (candidate 0 or 1)\n",
    "- Prompt dataset\n",
    "  - Input prompt only, no response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236bce0e",
   "metadata": {},
   "source": [
    "#### Preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3048b1b5-a01c-4c89-af5a-ce8f47d13218",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "preference_dataset_path = 'sample_preference.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7822c372-b9d0-46c0-86c3-dc38508262e3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb35514-6e2b-433c-a6f3-9411846fd2a6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "preference_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35bcc873-cd6a-4108-9c4a-47b7d27faab7",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "with open(preference_dataset_path) as f:\n",
    "    for line in f:\n",
    "        preference_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2290d9",
   "metadata": {},
   "source": [
    "- Print out to explore the preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57964e85-d4bd-4b35-b437-e51a4493eb33",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "sample_1 = preference_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bff834-4c5e-46c4-8887-d3a29cc8de86",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sample_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b473d0-bf39-4f8b-99e5-d6f795f33b83",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_text', 'candidate_0', 'candidate_1', 'choice'])\n"
     ]
    }
   ],
   "source": [
    "# This dictionary has four keys\n",
    "print(sample_1.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d524bb",
   "metadata": {},
   "source": [
    "- Key: 'input_test' is a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630d6337-0e6c-4ccb-987a-7d73de91c65a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I live right next to a huge university, and have been applying for a variety of jobs with them through their faceless electronic jobs portal (the \"click here to apply for this job\" type thing) for a few months. \\n\\nThe very first job I applied for, I got an interview that went just so-so. But then, I never heard back (I even looked up the number of the person who called me and called her back, left a voicemail, never heard anything).\\n\\nNow, when I\\'m applying for subsequent jobs - is it that same HR person who is seeing all my applications?? Or are they forwarded to the specific departments?\\n\\nI\\'ve applied for five jobs there in the last four months, all the resumes and cover letters tailored for each open position. Is this hurting my chances? I never got another interview there, for any of the positions. [summary]: '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb97174-bb2b-400a-b76a-81428063b76a",
   "metadata": {
    "height": 62
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plan something in those circumstances. [summary]: '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try with another examples from the list, and discover that all data end the same way \"[summary]:\"\n",
    "preference_data[2]['input_text'][-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78232d32",
   "metadata": {},
   "source": [
    "- Print 'candidate_0' and 'candidate_1', these are the completions for the same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a67ab282-3495-4aab-a43a-309978e03529",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_0:\n",
      " When applying through a massive job portal, is just one HR person seeing ALL of them?\n",
      "\n",
      "candidate_1:\n",
      " When applying to many jobs through a single university jobs portal, is just one HR person reading ALL my applications?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"candidate_0:\\n{sample_1.get('candidate_0')}\\n\")\n",
    "print(f\"candidate_1:\\n{sample_1.get('candidate_1')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3cc61",
   "metadata": {},
   "source": [
    "- Print 'choice', this is the human labeler's preference for the results completions (candidate_0 and candidate_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dae5b1cb-5411-462c-a122-bbb6264e4111",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choice: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"choice: {sample_1.get('choice')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda6787",
   "metadata": {},
   "source": [
    "#### Prompt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c2785a-87df-4bc7-adb8-ccbdfff7b819",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prompt_dataset_path = 'sample_prompt.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa3fd8ef-c9f3-4bc3-9404-cbe91fcae150",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "prompt_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0e47624-472f-4f20-8f02-219b38e166ee",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "with open(prompt_dataset_path) as f:\n",
    "    for line in f:\n",
    "        prompt_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1c90028-5da8-435d-a203-92a661154598",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many prompts there are in this dataset\n",
    "len(prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fd3a7",
   "metadata": {},
   "source": [
    "**Note**: It is important that the prompts in both datasets, the preference and the prompt, come from the same distribution. \n",
    "\n",
    "For this lesson, all the prompts come from the same dataset of [Reddit posts](https://github.com/openai/summarize-from-feedback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff6da85e-5b6d-4d68-bb8e-70716205f28a",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Function to print the information in the prompt dataset with a better visualization\n",
    "def print_d(d):\n",
    "    for key, val in d.items():        \n",
    "        print(f\"key:{key}\\nval:{val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e665d332-38a2-4b8c-be5a-6e4c6c3392b1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:input_text\n",
      "val:I noticed this the very first day! I took a picture of it to send to one of my friends who is a fellow redditor. Later when I was getting to know my suitemates, I asked them if they ever used reddit, and they showed me the stencil they used to spray that! Along with the lion which is his trademark. \n",
      " But [summary]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_d(prompt_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9825d214-13a1-41c0-8280-b584d2f3bbd0",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:input_text\n",
      "val:Nooooooo, I loved my health class! My teacher was amazing! Most days we just went outside and played and the facility allowed it because the health teacher's argument was that teens need to spend time outside everyday and he let us do that. The other days were spent inside with him teaching us how to live a healthy lifestyle. He had guest speakers come in and reach us about nutrition and our final was open book...if we even had a final.... [summary]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try with another prompt from the list \n",
    "print_d(prompt_data[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
