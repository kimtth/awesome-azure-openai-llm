{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293bcfbc-0883-4d68-be80-32329f3ca049",
   "metadata": {},
   "source": [
    "# Lab 3 - Query Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5536f0-651c-40e7-aa15-27ee0cda80b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_utils import load_chroma, word_wrap, project_embeddings\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748b16d-d4a7-49c3-a48a-57dcfc42acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "chroma_collection = load_chroma(filename='microsoft_annual_report_2022.pdf', collection_name='microsoft_annual_report_2022', embedding_function=embedding_function)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338ec83-6301-41a5-9ab1-e5d583306a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a86f8-2fe2-4682-bdaf-c15129ed1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "embeddings = chroma_collection.get(include=['embeddings'])['embeddings']\n",
    "umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(embeddings)\n",
    "projected_dataset_embeddings = project_embeddings(embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cafb52-7634-4e42-a334-c4d37259c951",
   "metadata": {},
   "source": [
    "## Expansion with generated answers\n",
    "\n",
    "https://arxiv.org/abs/2305.03653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a13d14-4484-46f0-8e67-277337f9d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_query_generated(query, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Provide an example answer to the given question, that might be found in a document like an annual report. \"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ] \n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6c8c5-9ce4-44d0-9223-6fdd77871f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"Was there significant turnover in the executive team?\"\n",
    "hypothetical_answer = augment_query_generated(original_query)\n",
    "\n",
    "joint_query = f\"{original_query} {hypothetical_answer}\"\n",
    "print(word_wrap(joint_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdb54db-a442-423c-b006-c33a257cd7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_collection.query(query_texts=joint_query, n_results=5, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for doc in retrieved_documents:\n",
    "    print(word_wrap(doc))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a84aa-1d93-4e97-9b2d-d59c46355338",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_embeddings = results['embeddings'][0]\n",
    "original_query_embedding = embedding_function([original_query])\n",
    "augmented_query_embedding = embedding_function([joint_query])\n",
    "\n",
    "projected_original_query_embedding = project_embeddings(original_query_embedding, umap_transform)\n",
    "projected_augmented_query_embedding = project_embeddings(augmented_query_embedding, umap_transform)\n",
    "projected_retrieved_embeddings = project_embeddings(retrieved_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ed8ca-6640-4c09-9cb3-9de5e7cf46dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the projected query and retrieved documents in the embedding space\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(projected_retrieved_embeddings[:, 0], projected_retrieved_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "plt.scatter(projected_original_query_embedding[:, 0], projected_original_query_embedding[:, 1], s=150, marker='X', color='r')\n",
    "plt.scatter(projected_augmented_query_embedding[:, 0], projected_augmented_query_embedding[:, 1], s=150, marker='X', color='orange')\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'{original_query}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24007a5a-4258-4f3d-8d14-d5b01bfa5cd0",
   "metadata": {},
   "source": [
    "## Expansion with multiple queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f2758-0f5a-49e5-b1fa-517b91324575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_multiple_query(query, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about an annual report. \"\n",
    "            \"Suggest up to five additional related questions to help them find the information they need, for the provided question. \"\n",
    "            \"Suggest only short questions without compound sentences. Suggest a variety of questions that cover different aspects of the topic.\"\n",
    "            \"Make sure they are complete questions, and that they are related to the original question.\"\n",
    "            \"Output one question per line. Do not number the questions.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    content = content.split(\"\\n\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee59493-8a99-4da8-b94f-4747efcfc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"What were the most important factors that contributed to increases in revenue?\"\n",
    "augmented_queries = augment_multiple_query(original_query)\n",
    "\n",
    "for query in augmented_queries:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eda9bc-ae76-4db6-9e0c-ae099d852d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [original_query] + augmented_queries\n",
    "results = chroma_collection.query(query_texts=queries, n_results=5, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents']\n",
    "\n",
    "# Deduplicate the retrieved documents\n",
    "unique_documents = set()\n",
    "for documents in retrieved_documents:\n",
    "    for document in documents:\n",
    "        unique_documents.add(document)\n",
    "\n",
    "for i, documents in enumerate(retrieved_documents):\n",
    "    print(f\"Query: {queries[i]}\")\n",
    "    print('')\n",
    "    print(\"Results:\")\n",
    "    for doc in documents:\n",
    "        print(word_wrap(doc))\n",
    "        print('')\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1183e75-4c65-422e-bc47-48010d8b29c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query_embedding = embedding_function([original_query])\n",
    "augmented_query_embeddings = embedding_function(augmented_queries)\n",
    "\n",
    "project_original_query = project_embeddings(original_query_embedding, umap_transform)\n",
    "project_augmented_queries = project_embeddings(augmented_query_embeddings, umap_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd85cc-8898-41ed-a0aa-bd8a33fc565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_embeddings = results['embeddings']\n",
    "result_embeddings = [item for sublist in result_embeddings for item in sublist]\n",
    "projected_result_embeddings = project_embeddings(result_embeddings, umap_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65337e9-85ee-47f7-89fd-7fe77cd0e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10, color='gray')\n",
    "plt.scatter(project_augmented_queries[:, 0], project_augmented_queries[:, 1], s=150, marker='X', color='orange')\n",
    "plt.scatter(projected_result_embeddings[:, 0], projected_result_embeddings[:, 1], s=100, facecolors='none', edgecolors='g')\n",
    "plt.scatter(project_original_query[:, 0], project_original_query[:, 1], s=150, marker='X', color='r')\n",
    "\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title(f'{original_query}')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7794092-4195-4cf3-9eab-11c9c05a26b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cab7a1-1be7-45f0-83b7-543e48f83901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0343be-73c9-4aed-83b0-aba09569ac87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f3e33-e517-4f6b-8b38-c47c1e3d40b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16fdcb1-57d0-4f04-af8f-7c7fc594d947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe7893-9cbc-43c5-94ef-cbf8f5d68cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9524b-1085-4bdf-a161-39f11397dc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189f088-b58e-4583-9590-afdfa624cf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26a01a-4575-446b-b8dc-a8c5ab153172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950575b-b69d-46a3-8c91-c7af89f5c204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f123ad8-b2e8-4a25-8b42-a520ecaf566b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c04587-d1de-419c-a213-2e3eb67dc33d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3155972-824e-4ebe-a692-2227c113c5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8144a4a-85f6-4800-87f9-36a1b6ceda1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0b18e-12a0-4ac0-97dd-8618b22e7dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca7e7c-4b47-4652-9b46-a40b3dffa5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e7d67-7f51-41c4-8e25-edbaa02d0bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188e886-d406-406f-b234-f5c3353a77a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bb286-2694-4ed4-8466-46865e997ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876084b-4038-4b0c-8ec8-8294a86adfc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac542e1-b094-431f-9611-cf7e36d3f0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6114b-c09d-4173-a623-9a08aaf63e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10ab65-b351-4f4b-b7d2-63474acfb9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f3d81-cbdb-4ba4-8d49-85747fdfded8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37847448-c9f6-4f51-bf06-f7809964a8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcefc87-0964-4b94-946b-2145781ad606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc994bc-7b1e-476a-9df9-300a3e374882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5f5d5-acb7-4b0a-93ef-e61306708e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e4b33f-d8fb-4f3a-b884-8b43a3766583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a480a2-2c29-4a01-80dd-ee41934b7901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127c2bf-0d15-4b62-b46a-f7a17ad2ec92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ded129-a637-4269-a116-550fe9a90570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7ee44-7b29-483f-a3f2-cc9d8e18880e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e450dd8-9719-42c6-8c3c-33cac910e0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
